from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import io
import json
from typing import List, Dict, Any
from datetime import datetime
import uuid

app = FastAPI(title="DevSecOps Tools")

# CORS middleware –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å React frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


def read_file(file: UploadFile) -> pd.DataFrame:
    """–ß–∏—Ç–∞–µ—Ç CSV –∏–ª–∏ XLSX —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame"""
    content = file.file.read()

    if file.filename.endswith('.csv'):
        return pd.read_csv(io.BytesIO(content))
    elif file.filename.endswith('.xlsx'):
        return pd.read_excel(io.BytesIO(content))
    else:
        raise HTTPException(status_code=400, detail="Unsupported file format. Use CSV or XLSX")


def migrate_comments(source_df: pd.DataFrame, target_df: pd.DataFrame) -> tuple[pd.DataFrame, Dict[str, Any]]:
    """
    –ü–µ—Ä–µ–Ω–æ—Å–∏—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏–∑ source_df –≤ target_df –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é CVE ID –∏ Project

    Args:
        source_df: –¢–∞–±–ª–∏—Ü–∞ 1 —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ (—Å—Ç–∞—Ä–∞—è –≤—ã–≥—Ä—É–∑–∫–∞)
        target_df: –¢–∞–±–ª–∏—Ü–∞ 2 (–Ω–æ–≤–∞—è –≤—ã–≥—Ä—É–∑–∫–∞)

    Returns:
        tuple: (DataFrame —Å –ø–µ—Ä–µ–Ω–µ—Å—ë–Ω–Ω—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏, –û—Ç—á–µ—Ç –æ –º–∏–≥—Ä–∞—Ü–∏–∏)
    """
    # –°–æ–∑–¥–∞—ë–º –∫–æ–ø–∏—é target_df
    result_df = target_df.copy()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    migration_log = {
        "status": "success",
        "timestamp": datetime.utcnow().isoformat() + "Z",
        "source_stats": {},
        "target_stats": {},
        "migration_stats": {},
        "project_mismatches": [],
        "warnings": [],
        "errors": []
    }

    # –ï—Å–ª–∏ –≤ target_df –Ω–µ—Ç —Å—Ç–æ–ª–±—Ü–∞ Comment, —Å–æ–∑–¥–∞—ë–º –µ–≥–æ
    if 'Comment' not in result_df.columns:
        result_df['Comment'] = ''
        migration_log["warnings"].append("–°—Ç–æ–ª–±–µ—Ü 'Comment' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ü–µ–ª–µ–≤–æ–º —Ñ–∞–π–ª–µ. –°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü.")

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
    source_cols = {col.lower().strip(): col for col in source_df.columns}
    target_cols = {col.lower().strip(): col for col in result_df.columns}

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
    cve_col_source = source_cols.get('cve id') or source_cols.get('cve')
    project_col_source = source_cols.get('project')
    comment_col_source = source_cols.get('comment')

    cve_col_target = target_cols.get('cve id') or target_cols.get('cve')
    project_col_target = target_cols.get('project')
    comment_col_target = target_cols.get('comment')

    if not all([cve_col_source, project_col_source, comment_col_source]):
        raise HTTPException(
            status_code=400,
            detail=f"Source file missing required columns (CVE ID, Project, Comment). Found: {list(source_df.columns)}"
        )

    if not all([cve_col_target, project_col_target]):
        raise HTTPException(
            status_code=400,
            detail=f"Target file missing required columns (CVE ID, Project). Found: {list(result_df.columns)}"
        )

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    migration_log["source_stats"] = {
        "total_rows": len(source_df),
        "cve_column": cve_col_source,
        "project_column": project_col_source,
        "comment_column": comment_col_source
    }

    migration_log["target_stats"] = {
        "total_rows": len(target_df),
        "cve_column": cve_col_target,
        "project_column": project_col_target,
        "comment_column": comment_col_target
    }

    # –°–æ–∑–¥–∞—ë–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
    # –ö–ª—é—á: (CVE ID, Project), –ó–Ω–∞—á–µ–Ω–∏–µ: Comment
    comment_map = {}
    source_projects = set()
    skipped_source_rows = 0

    for idx, row in source_df.iterrows():
        cve_id = str(row[cve_col_source]).strip() if pd.notna(row[cve_col_source]) else ''
        project = str(row[project_col_source]).strip() if pd.notna(row[project_col_source]) else ''
        comment = str(row[comment_col_source]).strip() if pd.notna(row[comment_col_source]) else ''

        if project:
            source_projects.add(project)

        if not cve_id or not project:
            skipped_source_rows += 1
            continue

        if comment:
            key = (cve_id, project)
            comment_map[key] = comment

    if skipped_source_rows > 0:
        migration_log["warnings"].append(
            f"–ü—Ä–æ–ø—É—â–µ–Ω–æ {skipped_source_rows} —Å—Ç—Ä–æ–∫ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ (–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç CVE ID –∏–ª–∏ Project)"
        )

    # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ —Å–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    matched_count = 0
    target_projects = set()
    skipped_target_rows = 0
    new_cves = []  # CVE, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ target, –Ω–æ –Ω–µ—Ç –≤ source

    for idx, row in result_df.iterrows():
        cve_id = str(row[cve_col_target]).strip() if pd.notna(row[cve_col_target]) else ''
        project = str(row[project_col_target]).strip() if pd.notna(row[project_col_target]) else ''

        if project:
            target_projects.add(project)

        if not cve_id or not project:
            skipped_target_rows += 1
            continue

        key = (cve_id, project)
        if key in comment_map:
            result_df.at[idx, comment_col_target] = comment_map[key]
            matched_count += 1
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–æ–≤—ã–π –ª–∏ —ç—Ç–æ CVE
            source_has_cve = any(cve_id == str(r[cve_col_source]).strip()
                                for _, r in source_df.iterrows()
                                if pd.notna(r[cve_col_source]))
            if not source_has_cve:
                new_cves.append({"cve": cve_id, "project": project})

    if skipped_target_rows > 0:
        migration_log["warnings"].append(
            f"–ü—Ä–æ–ø—É—â–µ–Ω–æ {skipped_target_rows} —Å—Ç—Ä–æ–∫ –≤ —Ü–µ–ª–µ–≤–æ–º —Ñ–∞–π–ª–µ (–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç CVE ID –∏–ª–∏ Project)"
        )

    # –ê–Ω–∞–ª–∏–∑ –Ω–µ—Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤
    projects_only_in_source = source_projects - target_projects
    projects_only_in_target = target_projects - source_projects
    common_projects = source_projects & target_projects

    if projects_only_in_source:
        migration_log["project_mismatches"] = {
            "projects_only_in_old_file": sorted(list(projects_only_in_source)),
            "count": len(projects_only_in_source),
            "note": "–≠—Ç–∏ –ø—Ä–æ–µ–∫—Ç—ã –±—ã–ª–∏ –≤ —Å—Ç–∞—Ä–æ–π –≤—ã–≥—Ä—É–∑–∫–µ, –Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –Ω–æ–≤–æ–π"
        }

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏
    migration_log["migration_stats"] = {
        "comments_migrated": matched_count,
        "comments_available_in_source": len(comment_map),
        "migration_rate_percent": round((matched_count / len(comment_map) * 100) if len(comment_map) > 0 else 0, 2),
        "unique_projects_in_source": len(source_projects),
        "unique_projects_in_target": len(target_projects),
        "common_projects": len(common_projects),
        "projects_only_in_source": len(projects_only_in_source),
        "projects_only_in_target": len(projects_only_in_target),
        "new_cves_in_target": len(new_cves),
        "new_cves_sample": new_cves[:5] if len(new_cves) > 5 else new_cves
    }

    if len(new_cves) > 0:
        migration_log["warnings"].append(
            f"–ù–∞–π–¥–µ–Ω–æ {len(new_cves)} –Ω–æ–≤—ã—Ö CVE –≤ —Ü–µ–ª–µ–≤–æ–º —Ñ–∞–π–ª–µ (–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –∏—Å—Ö–æ–¥–Ω–æ–º). –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ –≤—ã–≥—Ä—É–∑–∫–∏."
        )

    print(f"‚úÖ Migrated {matched_count} comments from {len(comment_map)} available")
    print(f"üìä Common projects: {len(common_projects)}")
    print(f"‚ö†Ô∏è  Projects only in source: {len(projects_only_in_source)}")
    print(f"‚ú® New CVEs in target: {len(new_cves)}")

    return result_df, migration_log


def convert_sbom_to_vex(sbom_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç CycloneDX SBOM –≤ CycloneDX VEX —Ñ–æ—Ä–º–∞—Ç

    Args:
        sbom_data: SBOM –≤ —Ñ–æ—Ä–º–∞—Ç–µ CycloneDX 1.6

    Returns:
        VEX –¥–æ–∫—É–º–µ–Ω—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ CycloneDX 1.6
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ CycloneDX —Ñ–æ—Ä–º–∞—Ç
    if sbom_data.get("bomFormat") != "CycloneDX":
        raise HTTPException(
            status_code=400,
            detail="Invalid SBOM format. Expected CycloneDX format"
        )

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π
    vulnerabilities = sbom_data.get("vulnerabilities", [])
    if not vulnerabilities:
        raise HTTPException(
            status_code=400,
            detail="SBOM does not contain any vulnerabilities"
        )

    # –°–æ–∑–¥–∞—ë–º VEX –¥–æ–∫—É–º–µ–Ω—Ç
    vex_document = {
        "$schema": "http://cyclonedx.org/schema/bom-1.6.schema.json",
        "bomFormat": "CycloneDX",
        "specVersion": sbom_data.get("specVersion", "1.6"),
        "serialNumber": f"urn:uuid:{uuid.uuid4()}",
        "version": 1,
        "metadata": {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "tools": {
                "components": [
                    {
                        "type": "application",
                        "name": "DevSecOps Tools - SBOM to VEX Converter",
                        "version": "1.0.0",
                        "description": "Converts CycloneDX SBOM to VEX format"
                    }
                ]
            }
        },
        "vulnerabilities": []
    }

    # –ö–æ–ø–∏—Ä—É–µ–º metadata –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ SBOM (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if "metadata" in sbom_data and "component" in sbom_data["metadata"]:
        vex_document["metadata"]["component"] = sbom_data["metadata"]["component"]

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —É—è–∑–≤–∏–º–æ—Å—Ç–∏
    for vuln in vulnerabilities:
        vex_vuln = {
            "id": vuln.get("id"),
            "bom-ref": vuln.get("bom-ref", f"vuln-{vuln.get('id')}"),
        }

        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ (source)
        if "source" in vuln:
            vex_vuln["source"] = vuln["source"]

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫–∏ (references)
        if "references" in vuln:
            vex_vuln["references"] = vuln["references"]

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–π—Ç–∏–Ω–≥–∏ (ratings)
        if "ratings" in vuln:
            vex_vuln["ratings"] = vuln["ratings"]

        # –î–æ–±–∞–≤–ª—è–µ–º CWE
        if "cwes" in vuln:
            vex_vuln["cwes"] = vuln["cwes"]

        # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
        if "description" in vuln:
            vex_vuln["description"] = vuln["description"]

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª–∏
        if "detail" in vuln:
            vex_vuln["detail"] = vuln["detail"]

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if "recommendation" in vuln:
            vex_vuln["recommendation"] = vuln["recommendation"]

        # –î–æ–±–∞–≤–ª—è–µ–º advisories
        if "advisories" in vuln:
            vex_vuln["advisories"] = vuln["advisories"]

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞—Ç—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        if "published" in vuln:
            vex_vuln["published"] = vuln["published"]
        if "updated" in vuln:
            vex_vuln["updated"] = vuln["updated"]

        # –î–æ–±–∞–≤–ª—è–µ–º credits
        if "credits" in vuln:
            vex_vuln["credits"] = vuln["credits"]

        # –î–æ–±–∞–≤–ª—è–µ–º tools
        if "tools" in vuln:
            vex_vuln["tools"] = vuln["tools"]

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º affects (–∑–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã)
        if "affects" in vuln:
            vex_vuln["affects"] = []
            for affect in vuln["affects"]:
                vex_affect = {
                    "ref": affect.get("ref")
                }

                # –î–æ–±–∞–≤–ª—è–µ–º –≤–µ—Ä—Å–∏–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                if "versions" in affect:
                    vex_affect["versions"] = affect["versions"]

                vex_vuln["affects"].append(vex_affect)

        # –î–æ–±–∞–≤–ª—è–µ–º properties (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞)
        if "properties" in vuln:
            vex_vuln["properties"] = vuln["properties"]

        # –î–æ–±–∞–≤–ª—è–µ–º analysis (–∞–Ω–∞–ª–∏–∑ —É—è–∑–≤–∏–º–æ—Å—Ç–∏)
        # –≠—Ç–æ –∫–ª—é—á–µ–≤–∞—è —á–∞—Å—Ç—å VEX - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç–∞—Ç—É—Å–µ –∏ –∞–Ω–∞–ª–∏–∑–µ
        if "analysis" in vuln:
            vex_vuln["analysis"] = vuln["analysis"]
        else:
            # –ï—Å–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            vex_vuln["analysis"] = {
                "state": "not_affected",
                "justification": "component_not_present",
                "detail": "Automated conversion from SBOM. Manual review required."
            }

        vex_document["vulnerabilities"].append(vex_vuln)

    return vex_document


@app.get("/")
async def root():
    return {"message": "DevSecOps Tools API", "version": "1.0.0"}


@app.post("/api/sbom-migrate")
async def sbom_migrate(
    source_file: UploadFile = File(..., description="–°—Ç–∞—Ä–∞—è –≤—ã–≥—Ä—É–∑–∫–∞ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏"),
    target_file: UploadFile = File(..., description="–ù–æ–≤–∞—è –≤—ã–≥—Ä—É–∑–∫–∞")
):
    """
    –ú–∏–≥—Ä–∏—Ä—É–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏–∑ —Å—Ç–∞—Ä–æ–π –≤—ã–≥—Ä—É–∑–∫–∏ –≤ –Ω–æ–≤—É—é –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é CVE ID –∏ Project
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –æ –º–∏–≥—Ä–∞—Ü–∏–∏
    """
    try:
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª—ã
        source_df = read_file(source_file)
        target_df = read_file(target_file)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –º–∏–≥—Ä–∞—Ü–∏—é —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        result_df, migration_log = migrate_comments(source_df, target_df)

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö
        migration_log["source_filename"] = source_file.filename
        migration_log["target_filename"] = target_file.filename
        migration_log["result_rows"] = len(result_df)
        migration_log["result_columns"] = list(result_df.columns)

        return migration_log

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/sbom-migrate/export")
async def sbom_migrate_export(
    source_file: UploadFile = File(...),
    target_file: UploadFile = File(...),
    export_format: str = "xlsx"
):
    """
    –ú–∏–≥—Ä–∏—Ä—É–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    """
    try:
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª—ã
        source_df = read_file(source_file)
        target_df = read_file(target_file)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –º–∏–≥—Ä–∞—Ü–∏—é
        result_df, migration_log = migrate_comments(source_df, target_df)

        # –í—ã–≤–æ–¥–∏–º –ª–æ–≥ –≤ –∫–æ–Ω—Å–æ–ª—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        print(f"\n{'='*80}")
        print(f"üìä Migration Log:")
        print(f"  Migrated: {migration_log['migration_stats']['comments_migrated']}")
        print(f"  Available: {migration_log['migration_stats']['comments_available_in_source']}")
        print(f"  Rate: {migration_log['migration_stats']['migration_rate_percent']}%")
        if migration_log.get('project_mismatches'):
            print(f"  ‚ö†Ô∏è  Project mismatches: {migration_log['project_mismatches']['count']}")
        print(f"{'='*80}\n")

        # –≠–∫—Å–ø–æ—Ä—Ç –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        output = io.BytesIO()

        if export_format.lower() == "csv":
            result_df.to_csv(output, index=False, encoding='utf-8-sig')
            output.seek(0)
            media_type = "text/csv"
            filename = "sbom_migrated.csv"
        elif export_format.lower() == "xlsx":
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                result_df.to_excel(writer, index=False, sheet_name='Migrated')
            output.seek(0)
            media_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            filename = "sbom_migrated.xlsx"
        else:
            raise HTTPException(status_code=400, detail="Invalid export format. Use 'csv' or 'xlsx'")

        return StreamingResponse(
            output,
            media_type=media_type,
            headers={"Content-Disposition": f"attachment; filename={filename}"}
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/sbom-to-vex")
async def sbom_to_vex(
    sbom_file: UploadFile = File(..., description="SBOM —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ CycloneDX 1.6")
):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç SBOM –≤ VEX —Ñ–æ—Ä–º–∞—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    """
    try:
        # –ß–∏—Ç–∞–µ–º SBOM —Ñ–∞–π–ª
        content = await sbom_file.read()
        sbom_data = json.loads(content)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ VEX
        vex_data = convert_sbom_to_vex(sbom_data)

        return {
            "status": "success",
            "sbom_vulnerabilities": len(sbom_data.get("vulnerabilities", [])),
            "vex_vulnerabilities": len(vex_data.get("vulnerabilities", [])),
            "sbom_components": len(sbom_data.get("components", [])),
            "sbom_format": sbom_data.get("bomFormat"),
            "sbom_version": sbom_data.get("specVersion"),
            "vex_serial_number": vex_data.get("serialNumber"),
            "conversion_timestamp": vex_data["metadata"]["timestamp"]
        }

    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="Invalid JSON format")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/sbom-to-vex/export")
async def sbom_to_vex_export(
    sbom_file: UploadFile = File(..., description="SBOM —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ CycloneDX 1.6")
):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç SBOM –≤ VEX —Ñ–æ—Ä–º–∞—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç JSON —Ñ–∞–π–ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    """
    try:
        # –ß–∏—Ç–∞–µ–º SBOM —Ñ–∞–π–ª
        content = await sbom_file.read()
        sbom_data = json.loads(content)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ VEX
        vex_data = convert_sbom_to_vex(sbom_data)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ JSON
        vex_json = json.dumps(vex_data, indent=2, ensure_ascii=False)

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ —Ñ–∞–π–ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        output = io.BytesIO(vex_json.encode('utf-8'))
        output.seek(0)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ SBOM
        original_name = sbom_file.filename.replace('.json', '')
        vex_filename = f"{original_name}_vex.json"

        return StreamingResponse(
            output,
            media_type="application/json",
            headers={"Content-Disposition": f"attachment; filename={vex_filename}"}
        )

    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="Invalid JSON format")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
