from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import io
import json
from typing import List, Dict, Any
from datetime import datetime
import uuid

app = FastAPI(title="DevSecOps Tools")

# CORS middleware –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å React frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


def read_file(file: UploadFile) -> pd.DataFrame:
    """–ß–∏—Ç–∞–µ—Ç CSV –∏–ª–∏ XLSX —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame"""
    content = file.file.read()

    if file.filename.endswith('.csv'):
        return pd.read_csv(io.BytesIO(content))
    elif file.filename.endswith('.xlsx'):
        return pd.read_excel(io.BytesIO(content))
    else:
        raise HTTPException(status_code=400, detail="Unsupported file format. Use CSV or XLSX")


def migrate_comments(source_df: pd.DataFrame, target_df: pd.DataFrame) -> tuple[pd.DataFrame, Dict[str, Any]]:
    """
    –ü–µ—Ä–µ–Ω–æ—Å–∏—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏–∑ source_df –≤ target_df –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é CVE ID –∏ Project

    Args:
        source_df: –¢–∞–±–ª–∏—Ü–∞ 1 —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ (—Å—Ç–∞—Ä–∞—è –≤—ã–≥—Ä—É–∑–∫–∞)
        target_df: –¢–∞–±–ª–∏—Ü–∞ 2 (–Ω–æ–≤–∞—è –≤—ã–≥—Ä—É–∑–∫–∞)

    Returns:
        tuple: (DataFrame —Å –ø–µ—Ä–µ–Ω–µ—Å—ë–Ω–Ω—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏, –û—Ç—á–µ—Ç –æ –º–∏–≥—Ä–∞—Ü–∏–∏)
    """
    # –°–æ–∑–¥–∞—ë–º –∫–æ–ø–∏—é target_df
    result_df = target_df.copy()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    migration_log = {
        "status": "success",
        "timestamp": datetime.utcnow().isoformat() + "Z",
        "source_stats": {},
        "target_stats": {},
        "migration_stats": {},
        "project_mismatches": [],
        "warnings": [],
        "errors": []
    }

    # –ï—Å–ª–∏ –≤ target_df –Ω–µ—Ç —Å—Ç–æ–ª–±—Ü–∞ Comment, —Å–æ–∑–¥–∞—ë–º –µ–≥–æ
    if 'Comment' not in result_df.columns:
        result_df['Comment'] = ''
        migration_log["warnings"].append("–°—Ç–æ–ª–±–µ—Ü 'Comment' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ü–µ–ª–µ–≤–æ–º —Ñ–∞–π–ª–µ. –°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü.")

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
    source_cols = {col.lower().strip(): col for col in source_df.columns}
    target_cols = {col.lower().strip(): col for col in result_df.columns}

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
    cve_col_source = source_cols.get('cve id') or source_cols.get('cve')
    project_col_source = source_cols.get('project')
    comment_col_source = source_cols.get('comment')

    cve_col_target = target_cols.get('cve id') or target_cols.get('cve')
    project_col_target = target_cols.get('project')
    comment_col_target = target_cols.get('comment')

    if not all([cve_col_source, project_col_source, comment_col_source]):
        raise HTTPException(
            status_code=400,
            detail=f"Source file missing required columns (CVE ID, Project, Comment). Found: {list(source_df.columns)}"
        )

    if not all([cve_col_target, project_col_target]):
        raise HTTPException(
            status_code=400,
            detail=f"Target file missing required columns (CVE ID, Project). Found: {list(result_df.columns)}"
        )

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    migration_log["source_stats"] = {
        "total_rows": len(source_df),
        "cve_column": cve_col_source,
        "project_column": project_col_source,
        "comment_column": comment_col_source
    }

    migration_log["target_stats"] = {
        "total_rows": len(target_df),
        "cve_column": cve_col_target,
        "project_column": project_col_target,
        "comment_column": comment_col_target
    }

    # –°–æ–∑–¥–∞—ë–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
    # –ö–ª—é—á: (CVE ID, Project), –ó–Ω–∞—á–µ–Ω–∏–µ: Comment
    comment_map = {}
    source_projects = set()
    skipped_source_rows = 0

    for idx, row in source_df.iterrows():
        cve_id = str(row[cve_col_source]).strip() if pd.notna(row[cve_col_source]) else ''
        project = str(row[project_col_source]).strip() if pd.notna(row[project_col_source]) else ''
        comment = str(row[comment_col_source]).strip() if pd.notna(row[comment_col_source]) else ''

        if project:
            source_projects.add(project)

        if not cve_id or not project:
            skipped_source_rows += 1
            continue

        if comment:
            key = (cve_id, project)
            comment_map[key] = comment

    if skipped_source_rows > 0:
        migration_log["warnings"].append(
            f"–ü—Ä–æ–ø—É—â–µ–Ω–æ {skipped_source_rows} —Å—Ç—Ä–æ–∫ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ (–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç CVE ID –∏–ª–∏ Project)"
        )

    # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ —Å–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    matched_count = 0
    target_projects = set()
    skipped_target_rows = 0
    new_cves = []  # CVE, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ target, –Ω–æ –Ω–µ—Ç –≤ source

    for idx, row in result_df.iterrows():
        cve_id = str(row[cve_col_target]).strip() if pd.notna(row[cve_col_target]) else ''
        project = str(row[project_col_target]).strip() if pd.notna(row[project_col_target]) else ''

        if project:
            target_projects.add(project)

        if not cve_id or not project:
            skipped_target_rows += 1
            continue

        key = (cve_id, project)
        if key in comment_map:
            result_df.at[idx, comment_col_target] = comment_map[key]
            matched_count += 1
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–æ–≤—ã–π –ª–∏ —ç—Ç–æ CVE
            source_has_cve = any(cve_id == str(r[cve_col_source]).strip()
                                for _, r in source_df.iterrows()
                                if pd.notna(r[cve_col_source]))
            if not source_has_cve:
                new_cves.append({"cve": cve_id, "project": project})

    if skipped_target_rows > 0:
        migration_log["warnings"].append(
            f"–ü—Ä–æ–ø—É—â–µ–Ω–æ {skipped_target_rows} —Å—Ç—Ä–æ–∫ –≤ —Ü–µ–ª–µ–≤–æ–º —Ñ–∞–π–ª–µ (–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç CVE ID –∏–ª–∏ Project)"
        )

    # –ê–Ω–∞–ª–∏–∑ –Ω–µ—Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤
    projects_only_in_source = source_projects - target_projects
    projects_only_in_target = target_projects - source_projects
    common_projects = source_projects & target_projects

    if projects_only_in_source:
        migration_log["project_mismatches"] = {
            "projects_only_in_old_file": sorted(list(projects_only_in_source)),
            "count": len(projects_only_in_source),
            "note": "–≠—Ç–∏ –ø—Ä–æ–µ–∫—Ç—ã –±—ã–ª–∏ –≤ —Å—Ç–∞—Ä–æ–π –≤—ã–≥—Ä—É–∑–∫–µ, –Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –Ω–æ–≤–æ–π"
        }

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏
    migration_log["migration_stats"] = {
        "comments_migrated": matched_count,
        "comments_available_in_source": len(comment_map),
        "migration_rate_percent": round((matched_count / len(comment_map) * 100) if len(comment_map) > 0 else 0, 2),
        "unique_projects_in_source": len(source_projects),
        "unique_projects_in_target": len(target_projects),
        "common_projects": len(common_projects),
        "projects_only_in_source": len(projects_only_in_source),
        "projects_only_in_target": len(projects_only_in_target),
        "new_cves_in_target": len(new_cves),
        "new_cves_sample": new_cves[:5] if len(new_cves) > 5 else new_cves
    }

    if len(new_cves) > 0:
        migration_log["warnings"].append(
            f"–ù–∞–π–¥–µ–Ω–æ {len(new_cves)} –Ω–æ–≤—ã—Ö CVE –≤ —Ü–µ–ª–µ–≤–æ–º —Ñ–∞–π–ª–µ (–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –∏—Å—Ö–æ–¥–Ω–æ–º). –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ –≤—ã–≥—Ä—É–∑–∫–∏."
        )

    print(f"‚úÖ Migrated {matched_count} comments from {len(comment_map)} available")
    print(f"üìä Common projects: {len(common_projects)}")
    print(f"‚ö†Ô∏è  Projects only in source: {len(projects_only_in_source)}")
    print(f"‚ú® New CVEs in target: {len(new_cves)}")

    return result_df, migration_log


def convert_sbom_to_vex(sbom_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç CycloneDX SBOM –≤ CycloneDX VEX —Ñ–æ—Ä–º–∞—Ç

    Args:
        sbom_data: SBOM –≤ —Ñ–æ—Ä–º–∞—Ç–µ CycloneDX 1.6

    Returns:
        VEX –¥–æ–∫—É–º–µ–Ω—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ CycloneDX 1.6
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ CycloneDX —Ñ–æ—Ä–º–∞—Ç
    if sbom_data.get("bomFormat") != "CycloneDX":
        raise HTTPException(
            status_code=400,
            detail="Invalid SBOM format. Expected CycloneDX format"
        )

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π
    vulnerabilities = sbom_data.get("vulnerabilities", [])
    if not vulnerabilities:
        raise HTTPException(
            status_code=400,
            detail="SBOM does not contain any vulnerabilities"
        )

    # –°–æ–∑–¥–∞—ë–º VEX –¥–æ–∫—É–º–µ–Ω—Ç
    vex_document = {
        "$schema": "http://cyclonedx.org/schema/bom-1.6.schema.json",
        "bomFormat": "CycloneDX",
        "specVersion": sbom_data.get("specVersion", "1.6"),
        "serialNumber": f"urn:uuid:{uuid.uuid4()}",
        "version": 1,
        "metadata": {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "tools": {
                "components": [
                    {
                        "type": "application",
                        "name": "DevSecOps Tools - SBOM to VEX Converter",
                        "version": "1.0.0",
                        "description": "Converts CycloneDX SBOM to VEX format"
                    }
                ]
            }
        },
        "vulnerabilities": []
    }

    # –ö–æ–ø–∏—Ä—É–µ–º metadata –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ SBOM (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if "metadata" in sbom_data and "component" in sbom_data["metadata"]:
        vex_document["metadata"]["component"] = sbom_data["metadata"]["component"]

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —É—è–∑–≤–∏–º–æ—Å—Ç–∏
    for vuln in vulnerabilities:
        vex_vuln = {
            "id": vuln.get("id"),
            "bom-ref": vuln.get("bom-ref", f"vuln-{vuln.get('id')}"),
        }

        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ (source)
        if "source" in vuln:
            vex_vuln["source"] = vuln["source"]

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫–∏ (references)
        if "references" in vuln:
            vex_vuln["references"] = vuln["references"]

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–π—Ç–∏–Ω–≥–∏ (ratings)
        if "ratings" in vuln:
            vex_vuln["ratings"] = vuln["ratings"]

        # –î–æ–±–∞–≤–ª—è–µ–º CWE
        if "cwes" in vuln:
            vex_vuln["cwes"] = vuln["cwes"]

        # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
        if "description" in vuln:
            vex_vuln["description"] = vuln["description"]

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª–∏
        if "detail" in vuln:
            vex_vuln["detail"] = vuln["detail"]

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if "recommendation" in vuln:
            vex_vuln["recommendation"] = vuln["recommendation"]

        # –î–æ–±–∞–≤–ª—è–µ–º advisories
        if "advisories" in vuln:
            vex_vuln["advisories"] = vuln["advisories"]

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞—Ç—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        if "published" in vuln:
            vex_vuln["published"] = vuln["published"]
        if "updated" in vuln:
            vex_vuln["updated"] = vuln["updated"]

        # –î–æ–±–∞–≤–ª—è–µ–º credits
        if "credits" in vuln:
            vex_vuln["credits"] = vuln["credits"]

        # –î–æ–±–∞–≤–ª—è–µ–º tools
        if "tools" in vuln:
            vex_vuln["tools"] = vuln["tools"]

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º affects (–∑–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã)
        if "affects" in vuln:
            vex_vuln["affects"] = []
            for affect in vuln["affects"]:
                vex_affect = {
                    "ref": affect.get("ref")
                }

                # –î–æ–±–∞–≤–ª—è–µ–º –≤–µ—Ä—Å–∏–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                if "versions" in affect:
                    vex_affect["versions"] = affect["versions"]

                vex_vuln["affects"].append(vex_affect)

        # –î–æ–±–∞–≤–ª—è–µ–º properties (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞)
        if "properties" in vuln:
            vex_vuln["properties"] = vuln["properties"]

        # –î–æ–±–∞–≤–ª—è–µ–º analysis (–∞–Ω–∞–ª–∏–∑ —É—è–∑–≤–∏–º–æ—Å—Ç–∏)
        # –≠—Ç–æ –∫–ª—é—á–µ–≤–∞—è —á–∞—Å—Ç—å VEX - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç–∞—Ç—É—Å–µ –∏ –∞–Ω–∞–ª–∏–∑–µ
        if "analysis" in vuln:
            vex_vuln["analysis"] = vuln["analysis"]
        else:
            # –ï—Å–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            vex_vuln["analysis"] = {
                "state": "not_affected",
                "justification": "component_not_present",
                "detail": "Automated conversion from SBOM. Manual review required."
            }

        vex_document["vulnerabilities"].append(vex_vuln)

    return vex_document


def convert_xlsx_to_vex(df: pd.DataFrame, product_name: str = None, product_version: str = None) -> Dict[str, Any]:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç XLSX —Ç–∞–±–ª–∏—Ü—É —Å —É—è–∑–≤–∏–º–æ—Å—Ç—è–º–∏ –≤ CycloneDX VEX —Ñ–æ—Ä–º–∞—Ç

    Args:
        df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏–∑ NBSS —ç–∫—Å–ø–æ—Ä—Ç–∞
        product_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        product_version: –í–µ—Ä—Å–∏—è –ø—Ä–æ–¥—É–∫—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    Returns:
        VEX –¥–æ–∫—É–º–µ–Ω—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ CycloneDX 1.6
    """

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    required_columns = ['CVE ID', 'Dependency name', 'Dependency version']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        raise HTTPException(
            status_code=400,
            detail=f"Missing required columns: {', '.join(missing_columns)}"
        )

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–æ
    if not product_name and 'Project' in df.columns:
        projects = df['Project'].dropna().unique()
        if len(projects) > 0:
            product_name = f"Multi-Project Analysis ({len(projects)} projects)"

    if not product_name:
        product_name = "SBOM Analysis"

    # –°–æ–∑–¥–∞—ë–º VEX –¥–æ–∫—É–º–µ–Ω—Ç
    vex_document = {
        "$schema": "http://cyclonedx.org/schema/bom-1.6.schema.json",
        "bomFormat": "CycloneDX",
        "specVersion": "1.6",
        "serialNumber": f"urn:uuid:{uuid.uuid4()}",
        "version": 1,
        "metadata": {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "tools": {
                "components": [
                    {
                        "type": "application",
                        "name": "DevSecOps Tools - XLSX to VEX Converter",
                        "version": "1.1.0",
                        "description": "Converts vulnerability analysis XLSX to CycloneDX VEX format"
                    }
                ]
            },
            "component": {
                "type": "application",
                "name": product_name,
                "version": product_version if product_version else "unknown"
            }
        },
        "vulnerabilities": []
    }

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ —É—è–∑–≤–∏–º–æ—Å—Ç—å
    for idx, row in df.iterrows():
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ CVE ID
        cve_id = row.get('CVE ID')
        if pd.isna(cve_id):
            continue

        # –ë–∞–∑–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —É—è–∑–≤–∏–º–æ—Å—Ç–∏
        vex_vuln = {
            "id": str(cve_id),
            "bom-ref": f"vuln-{idx}-{cve_id}"
        }

        # –ò—Å—Ç–æ—á–Ω–∏–∫ —É—è–∑–≤–∏–º–æ—Å—Ç–∏
        source_data = {"name": "NVD"}
        if not pd.isna(row.get('CVE Link')):
            source_data["url"] = str(row['CVE Link'])
        vex_vuln["source"] = source_data

        # –°—Å—ã–ª–∫–∏ (references)
        references = []
        if not pd.isna(row.get('CVE Link')):
            references.append({
                "id": str(cve_id),
                "source": {"name": "NVD", "url": str(row['CVE Link'])}
            })
        if not pd.isna(row.get('GHSA ID')) and not pd.isna(row.get('GHSA Link')):
            references.append({
                "id": str(row['GHSA ID']),
                "source": {"name": "GHSA", "url": str(row['GHSA Link'])}
            })
        if references:
            vex_vuln["references"] = references

        # –†–µ–π—Ç–∏–Ω–≥–∏ (ratings) - CVSS
        ratings = []

        # CVSS 3
        if not pd.isna(row.get('CVSS 3 Score')):
            rating = {
                "source": {"name": "NVD"},
                "score": float(row['CVSS 3 Score']),
                "method": "CVSSv3"
            }
            if not pd.isna(row.get('CVSS 3 Severity')):
                rating["severity"] = str(row['CVSS 3 Severity']).lower()
            if not pd.isna(row.get('CVSS 3 Metrics')):
                rating["vector"] = str(row['CVSS 3 Metrics'])
            ratings.append(rating)

        # CVSS 2 (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if not pd.isna(row.get('CVSS 2 Score')):
            rating = {
                "source": {"name": "NVD"},
                "score": float(row['CVSS 2 Score']),
                "method": "CVSSv2"
            }
            if not pd.isna(row.get('CVSS 2 Severity')):
                rating["severity"] = str(row['CVSS 2 Severity']).lower()
            if not pd.isna(row.get('CVSS 2 Metrics')):
                rating["vector"] = str(row['CVSS 2 Metrics'])
            ratings.append(rating)

        if ratings:
            vex_vuln["ratings"] = ratings

        # CWE
        if not pd.isna(row.get('CWEs')):
            cwes_str = str(row['CWEs'])
            # –ü–∞—Ä—Å–∏–º CWE: –º–æ–∂–µ—Ç –±—ã—Ç—å "CWE-79" –∏–ª–∏ "CWE-79, CWE-80"
            cwe_list = []
            for cwe in cwes_str.split(','):
                cwe = cwe.strip()
                if cwe.startswith('CWE-'):
                    try:
                        cwe_id = int(cwe.replace('CWE-', ''))
                        cwe_list.append(cwe_id)
                    except ValueError:
                        pass
            if cwe_list:
                vex_vuln["cwes"] = cwe_list

        # –û–ø–∏—Å–∞–Ω–∏–µ
        if not pd.isna(row.get('Summary')):
            vex_vuln["description"] = str(row['Summary'])

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        if not pd.isna(row.get('Fixed version')):
            vex_vuln["recommendation"] = f"Update to version {row['Fixed version']}"

        # –î–∞—Ç—ã
        if not pd.isna(row.get('Published')):
            try:
                published = pd.to_datetime(row['Published'])
                vex_vuln["published"] = published.isoformat() + "Z"
            except:
                pass

        if not pd.isna(row.get('Updated')):
            try:
                updated = pd.to_datetime(row['Updated'])
                vex_vuln["updated"] = updated.isoformat() + "Z"
            except:
                pass

        # Properties (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)
        properties = []

        if not pd.isna(row.get('Technology')):
            properties.append({
                "name": "technology",
                "value": str(row['Technology'])
            })

        if not pd.isna(row.get('Relation')):
            properties.append({
                "name": "dependency_relation",
                "value": str(row['Relation'])
            })

        if not pd.isna(row.get('Env')):
            properties.append({
                "name": "environment",
                "value": str(row['Env'])
            })

        if not pd.isna(row.get('Project')):
            properties.append({
                "name": "project",
                "value": str(row['Project'])
            })

        if not pd.isna(row.get('Has exploit')):
            has_exploit = row['Has exploit']
            if isinstance(has_exploit, bool):
                properties.append({
                    "name": "has_exploit",
                    "value": str(has_exploit).lower()
                })

        if properties:
            vex_vuln["properties"] = properties

        # –ó–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (affects)
        affects = []

        dependency_name = row.get('Dependency name')
        dependency_version = row.get('Dependency version')

        if not pd.isna(dependency_name):
            affect = {
                "ref": f"pkg:{dependency_name.replace(':', '/')}@{dependency_version if not pd.isna(dependency_version) else 'unknown'}"
            }

            # –í–µ—Ä—Å–∏–∏
            if not pd.isna(dependency_version):
                versions = [{
                    "version": str(dependency_version),
                    "status": "affected"
                }]

                # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
                if not pd.isna(row.get('Fixed version')):
                    versions.append({
                        "version": str(row['Fixed version']),
                        "status": "unaffected"
                    })

                affect["versions"] = versions

            affects.append(affect)

        if affects:
            vex_vuln["affects"] = affects

        # –ö–õ–Æ–ß–ï–í–û–ï: VEX Analysis (state, justification, response, detail)
        analysis = {}

        # State (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ –¥–ª—è VEX)
        state = row.get('State')
        if not pd.isna(state):
            state_str = str(state).strip()
            # –í–∞–ª–∏–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: exploitable, in_triage, false_positive, not_affected, resolved
            valid_states = ['exploitable', 'in_triage', 'false_positive', 'not_affected', 'resolved']
            if state_str in valid_states:
                analysis["state"] = state_str
            else:
                # –ï—Å–ª–∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ, —Å—Ç–∞–≤–∏–º in_triage
                analysis["state"] = "in_triage"
        else:
            # –ï—Å–ª–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–µ—Ç, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            analysis["state"] = "in_triage"

        # Justification (—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è not_affected)
        justification = row.get('Justification')
        if not pd.isna(justification):
            justification_str = str(justification).strip()
            # –í–∞–ª–∏–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è CycloneDX VEX justification
            valid_justifications = [
                'code_not_present', 'code_not_reachable', 'requires_configuration',
                'requires_dependency', 'requires_environment', 'protected_by_compiler',
                'protected_by_mitigating_control'
            ]
            if justification_str in valid_justifications:
                analysis["justification"] = justification_str

        # Response (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        response = row.get('Response')
        if not pd.isna(response):
            response_str = str(response).strip()
            # –í–∞–ª–∏–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: can_not_fix, will_not_fix, update, rollback, workaround_available
            valid_responses = ['can_not_fix', 'will_not_fix', 'update', 'rollback', 'workaround_available']
            if response_str in valid_responses:
                analysis["response"] = response_str

        # Detail (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)
        detail = row.get('Detail')
        if not pd.isna(detail):
            analysis["detail"] = str(detail)

        # –ï—Å–ª–∏ –Ω–µ—Ç detail, –Ω–æ –µ—Å—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        if "detail" not in analysis:
            detail_parts = []
            if not pd.isna(row.get('Files')):
                detail_parts.append(f"Files: {row['Files']}")
            if detail_parts:
                analysis["detail"] = "; ".join(detail_parts)

        vex_vuln["analysis"] = analysis

        # –î–æ–±–∞–≤–ª—è–µ–º —É—è–∑–≤–∏–º–æ—Å—Ç—å –≤ –¥–æ–∫—É–º–µ–Ω—Ç
        vex_document["vulnerabilities"].append(vex_vuln)

    return vex_document


@app.get("/")
async def root():
    return {"message": "DevSecOps Tools API", "version": "1.0.0"}


@app.post("/api/sbom-migrate")
async def sbom_migrate(
    source_file: UploadFile = File(..., description="–°—Ç–∞—Ä–∞—è –≤—ã–≥—Ä—É–∑–∫–∞ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏"),
    target_file: UploadFile = File(..., description="–ù–æ–≤–∞—è –≤—ã–≥—Ä—É–∑–∫–∞")
):
    """
    –ú–∏–≥—Ä–∏—Ä—É–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏–∑ —Å—Ç–∞—Ä–æ–π –≤—ã–≥—Ä—É–∑–∫–∏ –≤ –Ω–æ–≤—É—é –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é CVE ID –∏ Project
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –æ –º–∏–≥—Ä–∞—Ü–∏–∏
    """
    try:
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª—ã
        source_df = read_file(source_file)
        target_df = read_file(target_file)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –º–∏–≥—Ä–∞—Ü–∏—é —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        result_df, migration_log = migrate_comments(source_df, target_df)

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö
        migration_log["source_filename"] = source_file.filename
        migration_log["target_filename"] = target_file.filename
        migration_log["result_rows"] = len(result_df)
        migration_log["result_columns"] = list(result_df.columns)

        return migration_log

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/sbom-migrate/export")
async def sbom_migrate_export(
    source_file: UploadFile = File(...),
    target_file: UploadFile = File(...),
    export_format: str = "xlsx"
):
    """
    –ú–∏–≥—Ä–∏—Ä—É–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    """
    try:
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª—ã
        source_df = read_file(source_file)
        target_df = read_file(target_file)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –º–∏–≥—Ä–∞—Ü–∏—é
        result_df, migration_log = migrate_comments(source_df, target_df)

        # –í—ã–≤–æ–¥–∏–º –ª–æ–≥ –≤ –∫–æ–Ω—Å–æ–ª—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        print(f"\n{'='*80}")
        print(f"üìä Migration Log:")
        print(f"  Migrated: {migration_log['migration_stats']['comments_migrated']}")
        print(f"  Available: {migration_log['migration_stats']['comments_available_in_source']}")
        print(f"  Rate: {migration_log['migration_stats']['migration_rate_percent']}%")
        if migration_log.get('project_mismatches'):
            print(f"  ‚ö†Ô∏è  Project mismatches: {migration_log['project_mismatches']['count']}")
        print(f"{'='*80}\n")

        # –≠–∫—Å–ø–æ—Ä—Ç –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        output = io.BytesIO()

        if export_format.lower() == "csv":
            result_df.to_csv(output, index=False, encoding='utf-8-sig')
            output.seek(0)
            media_type = "text/csv"
            filename = "sbom_migrated.csv"
        elif export_format.lower() == "xlsx":
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                result_df.to_excel(writer, index=False, sheet_name='Migrated')
            output.seek(0)
            media_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            filename = "sbom_migrated.xlsx"
        else:
            raise HTTPException(status_code=400, detail="Invalid export format. Use 'csv' or 'xlsx'")

        return StreamingResponse(
            output,
            media_type=media_type,
            headers={"Content-Disposition": f"attachment; filename={filename}"}
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/sbom-to-vex")
async def sbom_to_vex(
    sbom_file: UploadFile = File(..., description="SBOM —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ CycloneDX 1.6")
):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç SBOM –≤ VEX —Ñ–æ—Ä–º–∞—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    """
    try:
        # –ß–∏—Ç–∞–µ–º SBOM —Ñ–∞–π–ª
        content = await sbom_file.read()
        sbom_data = json.loads(content)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ VEX
        vex_data = convert_sbom_to_vex(sbom_data)

        return {
            "status": "success",
            "sbom_vulnerabilities": len(sbom_data.get("vulnerabilities", [])),
            "vex_vulnerabilities": len(vex_data.get("vulnerabilities", [])),
            "sbom_components": len(sbom_data.get("components", [])),
            "sbom_format": sbom_data.get("bomFormat"),
            "sbom_version": sbom_data.get("specVersion"),
            "vex_serial_number": vex_data.get("serialNumber"),
            "conversion_timestamp": vex_data["metadata"]["timestamp"]
        }

    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="Invalid JSON format")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/sbom-to-vex/export")
async def sbom_to_vex_export(
    sbom_file: UploadFile = File(..., description="SBOM —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ CycloneDX 1.6")
):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç SBOM –≤ VEX —Ñ–æ—Ä–º–∞—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç JSON —Ñ–∞–π–ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    """
    try:
        # –ß–∏—Ç–∞–µ–º SBOM —Ñ–∞–π–ª
        content = await sbom_file.read()
        sbom_data = json.loads(content)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ VEX
        vex_data = convert_sbom_to_vex(sbom_data)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ JSON
        vex_json = json.dumps(vex_data, indent=2, ensure_ascii=False)

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ —Ñ–∞–π–ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        output = io.BytesIO(vex_json.encode('utf-8'))
        output.seek(0)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ SBOM
        original_name = sbom_file.filename.replace('.json', '')
        vex_filename = f"{original_name}_vex.json"

        return StreamingResponse(
            output,
            media_type="application/json",
            headers={"Content-Disposition": f"attachment; filename={vex_filename}"}
        )

    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="Invalid JSON format")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/xlsx-to-vex")
async def xlsx_to_vex(
    xlsx_file: UploadFile = File(..., description="XLSX —Ñ–∞–π–ª —Å —É—è–∑–≤–∏–º–æ—Å—Ç—è–º–∏"),
    product_name: str = None,
    product_version: str = None
):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç XLSX —Ñ–∞–π–ª —Å —É—è–∑–≤–∏–º–æ—Å—Ç—è–º–∏ –≤ VEX —Ñ–æ—Ä–º–∞—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    """
    try:
        # –ß–∏—Ç–∞–µ–º XLSX —Ñ–∞–π–ª
        df = read_file(xlsx_file)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ VEX
        vex_data = convert_xlsx_to_vex(df, product_name, product_version)

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ State
        state_stats = {}
        for vuln in vex_data["vulnerabilities"]:
            state = vuln.get("analysis", {}).get("state", "unknown")
            state_stats[state] = state_stats.get(state, 0) + 1

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ Justification
        justification_stats = {}
        for vuln in vex_data["vulnerabilities"]:
            justification = vuln.get("analysis", {}).get("justification")
            if justification:
                justification_stats[justification] = justification_stats.get(justification, 0) + 1

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø—Ä–æ–µ–∫—Ç–∞–º (–∏–∑ properties)
        project_stats = {}
        for vuln in vex_data["vulnerabilities"]:
            properties = vuln.get("properties", [])
            for prop in properties:
                if prop.get("name") == "project":
                    project = prop.get("value", "unknown")
                    project_stats[project] = project_stats.get(project, 0) + 1

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–º
        technology_stats = {}
        for vuln in vex_data["vulnerabilities"]:
            properties = vuln.get("properties", [])
            for prop in properties:
                if prop.get("name") == "technology":
                    technology = prop.get("value", "unknown")
                    technology_stats[technology] = technology_stats.get(technology, 0) + 1

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É—è–∑–≤–∏–º–æ—Å—Ç–∏ —Å —ç–∫—Å–ø–ª–æ–π—Ç–∞–º–∏
        has_exploit_count = 0
        for vuln in vex_data["vulnerabilities"]:
            properties = vuln.get("properties", [])
            for prop in properties:
                if prop.get("name") == "has_exploit" and prop.get("value") == "true":
                    has_exploit_count += 1
                    break

        return {
            "status": "success",
            "source_filename": xlsx_file.filename,
            "source_rows": len(df),
            "vex_vulnerabilities": len(vex_data.get("vulnerabilities", [])),
            "vex_serial_number": vex_data.get("serialNumber"),
            "vex_version": vex_data.get("specVersion"),
            "conversion_timestamp": vex_data["metadata"]["timestamp"],
            "product_name": vex_data["metadata"]["component"]["name"],
            "product_version": vex_data["metadata"]["component"]["version"],
            "statistics": {
                "state_distribution": state_stats,
                "justification_distribution": justification_stats,
                "project_distribution": project_stats,
                "technology_distribution": technology_stats,
                "has_exploit_count": has_exploit_count
            }
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/xlsx-to-vex/export")
async def xlsx_to_vex_export(
    xlsx_file: UploadFile = File(..., description="XLSX —Ñ–∞–π–ª —Å —É—è–∑–≤–∏–º–æ—Å—Ç—è–º–∏"),
    product_name: str = None,
    product_version: str = None
):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç XLSX —Ñ–∞–π–ª —Å —É—è–∑–≤–∏–º–æ—Å—Ç—è–º–∏ –≤ VEX —Ñ–æ—Ä–º–∞—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç JSON —Ñ–∞–π–ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    """
    try:
        # –ß–∏—Ç–∞–µ–º XLSX —Ñ–∞–π–ª
        df = read_file(xlsx_file)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ VEX
        vex_data = convert_xlsx_to_vex(df, product_name, product_version)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ JSON
        vex_json = json.dumps(vex_data, indent=2, ensure_ascii=False)

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ —Ñ–∞–π–ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        output = io.BytesIO(vex_json.encode('utf-8'))
        output.seek(0)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ XLSX
        original_name = xlsx_file.filename.replace('.xlsx', '').replace('.xls', '')
        vex_filename = f"{original_name}_vex.json"

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å
        print(f"\n{'='*80}")
        print(f"üìä XLSX to VEX Conversion:")
        print(f"  Source: {xlsx_file.filename}")
        print(f"  Rows: {len(df)}")
        print(f"  Vulnerabilities: {len(vex_data['vulnerabilities'])}")
        print(f"  Product: {vex_data['metadata']['component']['name']}")
        print(f"  Version: {vex_data['metadata']['component']['version']}")
        print(f"  Output: {vex_filename}")
        print(f"{'='*80}\n")

        return StreamingResponse(
            output,
            media_type="application/json",
            headers={"Content-Disposition": f"attachment; filename={vex_filename}"}
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
